{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "100本ノック 第5章"
      ],
      "metadata": {
        "id": "aiS7xWwVW0pi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "問４０"
      ],
      "metadata": {
        "id": "V196f2gKW7TG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ai.ja.zipをインストールし、解凍する\n",
        "!wget https://nlp100.github.io/data/ai.ja.zip\n",
        "!unzip ai.ja.zip\n",
        "\n",
        "# MeCabをインストール（CaboChaの実行に必要）\n",
        "!apt install mecab libmecab-dev mecab-ipadic-utf8\n",
        "\n",
        "# CRF++をインストール（CaboChaの実行に必要）\n",
        "FILE_ID = \"0B4y35FiV1wh7QVR6VXJ5dWExSTQ\"\n",
        "FILE_NAME = \"crfpp.tar.gz\"\n",
        "!wget 'https://docs.google.com/uc?export=download&id=$FILE_ID' -O $FILE_NAME\n",
        "!tar xvf crfpp.tar.gz\n",
        "%cd CRF++-0.58\n",
        "!./configure && make && make install && ldconfig\n",
        "%cd ..\n",
        "\n",
        "# CaboChaをインストール\n",
        "FILE_ID = \"0B4y35FiV1wh7SDd1Q1dUQkZQaUU\"\n",
        "FILE_NAME = \"cabocha-0.69.tar.bz2\"\n",
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=$FILE_ID' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=$FILE_ID\" -O $FILE_NAME && rm -rf /tmp/cookies.txt\n",
        "!tar -xvf cabocha-0.69.tar.bz2\n",
        "%cd cabocha-0.69\n",
        "!./configure -with-charset=utf-8 && make && make check && make install && ldconfig\n",
        "%cd ..\n",
        "\n",
        "#係り受け解析結果をai.ja.txt.parsedに保存\n",
        "!cabocha -f1 -o ai.ja.txt.parsed ai.ja.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3viqJTpW_Hj",
        "outputId": "2518ed91-cf7d-4104-8ece-a1d1ac89c7ac"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-08 05:44:18--  https://nlp100.github.io/data/ai.ja.zip\n",
            "Resolving nlp100.github.io (nlp100.github.io)... 185.199.111.153, 185.199.110.153, 185.199.109.153, ...\n",
            "Connecting to nlp100.github.io (nlp100.github.io)|185.199.111.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 17516 (17K) [application/zip]\n",
            "Saving to: ‘ai.ja.zip’\n",
            "\n",
            "\rai.ja.zip             0%[                    ]       0  --.-KB/s               \rai.ja.zip           100%[===================>]  17.11K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-12-08 05:44:19 (113 MB/s) - ‘ai.ja.zip’ saved [17516/17516]\n",
            "\n",
            "Archive:  ai.ja.zip\n",
            "  inflating: ai.ja.txt               \n",
            "  inflating: readme.ai.ja.md         \n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libmecab-dev is already the newest version (0.996-14build9).\n",
            "mecab-ipadic-utf8 is already the newest version (2.7.0-20070801+main-3).\n",
            "mecab is already the newest version (0.996-14build9).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 15 not upgraded.\n",
            "--2023-12-08 05:44:21--  https://docs.google.com/uc?export=download&id=$FILE_ID\n",
            "Resolving docs.google.com (docs.google.com)... 74.125.195.101, 74.125.195.102, 74.125.195.100, ...\n",
            "Connecting to docs.google.com (docs.google.com)|74.125.195.101|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2023-12-08 05:44:21 ERROR 404: Not Found.\n",
            "\n",
            "tar: This does not look like a tar archive\n",
            "\n",
            "gzip: stdin: unexpected end of file\n",
            "tar: Child returned status 1\n",
            "tar: Error is not recoverable: exiting now\n",
            "[Errno 2] No such file or directory: 'CRF++-0.58'\n",
            "/\n",
            "/bin/bash: line 1: ./configure: No such file or directory\n",
            "/\n",
            "--2023-12-08 05:44:22--  https://docs.google.com/uc?export=download&confirm=&id=0B4y35FiV1wh7SDd1Q1dUQkZQaUU\n",
            "Resolving docs.google.com (docs.google.com)... 74.125.195.101, 74.125.195.102, 74.125.195.100, ...\n",
            "Connecting to docs.google.com (docs.google.com)|74.125.195.101|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-04-74-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/5dp12772rp8f2s0ou28tbf52douvuu0j/1702014225000/13553212398903315502/*/0B4y35FiV1wh7SDd1Q1dUQkZQaUU?e=download&uuid=4946d675-a139-4ced-9b8f-d738461b53ef [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2023-12-08 05:44:22--  https://doc-04-74-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/5dp12772rp8f2s0ou28tbf52douvuu0j/1702014225000/13553212398903315502/*/0B4y35FiV1wh7SDd1Q1dUQkZQaUU?e=download&uuid=4946d675-a139-4ced-9b8f-d738461b53ef\n",
            "Resolving doc-04-74-docs.googleusercontent.com (doc-04-74-docs.googleusercontent.com)... 173.194.203.132, 2607:f8b0:400e:c05::84\n",
            "Connecting to doc-04-74-docs.googleusercontent.com (doc-04-74-docs.googleusercontent.com)|173.194.203.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 84638995 (81M) [application/x-bzip2]\n",
            "Saving to: ‘cabocha-0.69.tar.bz2’\n",
            "\n",
            "cabocha-0.69.tar.bz 100%[===================>]  80.72M   180MB/s    in 0.4s    \n",
            "\n",
            "2023-12-08 05:44:23 (180 MB/s) - ‘cabocha-0.69.tar.bz2’ saved [84638995/84638995]\n",
            "\n",
            "cabocha-0.69/\n",
            "cabocha-0.69/cabocha-config.in\n",
            "cabocha-0.69/compile\n",
            "cabocha-0.69/swig/\n",
            "cabocha-0.69/swig/version.h.in\n",
            "cabocha-0.69/swig/Makefile\n",
            "cabocha-0.69/swig/version.h\n",
            "cabocha-0.69/swig/CaboCha.i\n",
            "cabocha-0.69/missing\n",
            "cabocha-0.69/java/\n",
            "cabocha-0.69/java/test.java\n",
            "cabocha-0.69/java/Makefile\n",
            "cabocha-0.69/java/org/\n",
            "cabocha-0.69/java/org/chasen/\n",
            "cabocha-0.69/java/org/chasen/cabocha/\n",
            "cabocha-0.69/java/org/chasen/cabocha/FormatType.java\n",
            "cabocha-0.69/java/org/chasen/cabocha/OutputLayerType.java\n",
            "cabocha-0.69/java/org/chasen/cabocha/Token.java\n",
            "cabocha-0.69/java/org/chasen/cabocha/CaboChaConstants.java\n",
            "cabocha-0.69/java/org/chasen/cabocha/ParserType.java\n",
            "cabocha-0.69/java/org/chasen/cabocha/ParsingAlgorithm.java\n",
            "cabocha-0.69/java/org/chasen/cabocha/Chunk.java\n",
            "cabocha-0.69/java/org/chasen/cabocha/InputLayerType.java\n",
            "cabocha-0.69/java/org/chasen/cabocha/CaboCha.java\n",
            "cabocha-0.69/java/org/chasen/cabocha/CaboChaJNI.java\n",
            "cabocha-0.69/java/org/chasen/cabocha/PossetType.java\n",
            "cabocha-0.69/java/org/chasen/cabocha/Tree.java\n",
            "cabocha-0.69/java/org/chasen/cabocha/CharsetType.java\n",
            "cabocha-0.69/java/org/chasen/cabocha/Parser.java\n",
            "cabocha-0.69/java/CaboCha_wrap.cxx\n",
            "cabocha-0.69/ltmain.sh\n",
            "cabocha-0.69/config.guess\n",
            "cabocha-0.69/man/\n",
            "cabocha-0.69/man/Makefile.in\n",
            "cabocha-0.69/man/cabocha.1\n",
            "cabocha-0.69/man/Makefile.am\n",
            "cabocha-0.69/BSD\n",
            "cabocha-0.69/python/\n",
            "cabocha-0.69/python/test.py\n",
            "cabocha-0.69/python/CaboCha.py\n",
            "cabocha-0.69/python/CaboCha_wrap.cxx\n",
            "cabocha-0.69/python/setup.py\n",
            "cabocha-0.69/AUTHORS\n",
            "cabocha-0.69/ruby/\n",
            "cabocha-0.69/ruby/CaboCha_wrap.cpp\n",
            "cabocha-0.69/ruby/extconf.rb\n",
            "cabocha-0.69/ruby/test.rb\n",
            "cabocha-0.69/Makefile.in\n",
            "cabocha-0.69/NEWS\n",
            "cabocha-0.69/install-sh\n",
            "cabocha-0.69/cabocha.iss.in\n",
            "cabocha-0.69/ChangeLog\n",
            "cabocha-0.69/configure\n",
            "cabocha-0.69/src/\n",
            "cabocha-0.69/src/string_buffer.cpp\n",
            "cabocha-0.69/src/tree_allocator.cpp\n",
            "cabocha-0.69/src/dep.h\n",
            "cabocha-0.69/src/dep_learner.cpp\n",
            "cabocha-0.69/src/tree_allocator.h\n",
            "cabocha-0.69/src/svm.h\n",
            "cabocha-0.69/src/svm.cpp\n",
            "cabocha-0.69/src/ucstable.h\n",
            "cabocha-0.69/src/utils.h\n",
            "cabocha-0.69/src/selector.cpp\n",
            "cabocha-0.69/src/chunk_learner.cpp\n",
            "cabocha-0.69/src/string_buffer.h\n",
            "cabocha-0.69/src/ucs.cpp\n",
            "cabocha-0.69/src/ne.cpp\n",
            "cabocha-0.69/src/eval.cpp\n",
            "cabocha-0.69/src/cabocha.cpp\n",
            "cabocha-0.69/src/Makefile.in\n",
            "cabocha-0.69/src/scoped_ptr.h\n",
            "cabocha-0.69/src/chunker.h\n",
            "cabocha-0.69/src/normalizer.rule\n",
            "cabocha-0.69/src/common.h\n",
            "cabocha-0.69/src/normalizer_rule.sh\n",
            "cabocha-0.69/src/darts.h\n",
            "cabocha-0.69/src/learner.cpp\n",
            "cabocha-0.69/src/cabocha.h\n",
            "cabocha-0.69/src/morph.h\n",
            "cabocha-0.69/src/svm_learn.cpp\n",
            "cabocha-0.69/src/Makefile.msvc.in\n",
            "cabocha-0.69/src/timer.h\n",
            "cabocha-0.69/src/chunker.cpp\n",
            "cabocha-0.69/src/utils.cpp\n",
            "cabocha-0.69/src/param.h\n",
            "cabocha-0.69/src/winmain.h\n",
            "cabocha-0.69/src/normalizer.h\n",
            "cabocha-0.69/src/param.cpp\n",
            "cabocha-0.69/src/parser.cpp\n",
            "cabocha-0.69/src/ne.h\n",
            "cabocha-0.69/src/normalizer_rule.h\n",
            "cabocha-0.69/src/svm_learn.h\n",
            "cabocha-0.69/src/ucs.h\n",
            "cabocha-0.69/src/cabocha-model-index.cpp\n",
            "cabocha-0.69/src/mmap.h\n",
            "cabocha-0.69/src/analyzer.h\n",
            "cabocha-0.69/src/make.bat\n",
            "cabocha-0.69/src/tree.cpp\n",
            "cabocha-0.69/src/char_category.h\n",
            "cabocha-0.69/src/Makefile.am\n",
            "cabocha-0.69/src/dep.cpp\n",
            "cabocha-0.69/src/morph.cpp\n",
            "cabocha-0.69/src/selector_pat.h\n",
            "cabocha-0.69/src/cabocha-system-eval.cpp\n",
            "cabocha-0.69/src/cabocha-learn.cpp\n",
            "cabocha-0.69/src/stream_wrapper.h\n",
            "cabocha-0.69/src/selector.h\n",
            "cabocha-0.69/src/libcabocha.cpp\n",
            "cabocha-0.69/src/normalizer.cpp\n",
            "cabocha-0.69/src/freelist.h\n",
            "cabocha-0.69/perl/\n",
            "cabocha-0.69/perl/test.pl\n",
            "cabocha-0.69/perl/Makefile.PL\n",
            "cabocha-0.69/perl/CaboCha_wrap.o\n",
            "cabocha-0.69/perl/CaboCha.bs\n",
            "cabocha-0.69/perl/blib/\n",
            "cabocha-0.69/perl/blib/bin/\n",
            "cabocha-0.69/perl/blib/bin/.exists\n",
            "cabocha-0.69/perl/blib/arch/\n",
            "cabocha-0.69/perl/blib/arch/.exists\n",
            "cabocha-0.69/perl/blib/arch/auto/\n",
            "cabocha-0.69/perl/blib/arch/auto/CaboCha/\n",
            "cabocha-0.69/perl/blib/arch/auto/CaboCha/.exists\n",
            "cabocha-0.69/perl/blib/arch/auto/CaboCha/CaboCha.so\n",
            "cabocha-0.69/perl/blib/arch/auto/CaboCha/CaboCha.bs\n",
            "cabocha-0.69/perl/blib/lib/\n",
            "cabocha-0.69/perl/blib/lib/.exists\n",
            "cabocha-0.69/perl/blib/lib/auto/\n",
            "cabocha-0.69/perl/blib/lib/auto/CaboCha/\n",
            "cabocha-0.69/perl/blib/lib/auto/CaboCha/.exists\n",
            "cabocha-0.69/perl/blib/lib/CaboCha.pm\n",
            "cabocha-0.69/perl/blib/man1/\n",
            "cabocha-0.69/perl/blib/man1/.exists\n",
            "cabocha-0.69/perl/blib/script/\n",
            "cabocha-0.69/perl/blib/script/.exists\n",
            "cabocha-0.69/perl/blib/man3/\n",
            "cabocha-0.69/perl/blib/man3/.exists\n",
            "cabocha-0.69/perl/CaboCha_wrap.cxx\n",
            "cabocha-0.69/perl/pm_to_blib\n",
            "cabocha-0.69/perl/CaboCha.pm\n",
            "cabocha-0.69/perl/MYMETA.yml\n",
            "cabocha-0.69/config.rpath\n",
            "cabocha-0.69/TODO\n",
            "cabocha-0.69/configure.in\n",
            "cabocha-0.69/config.sub\n",
            "cabocha-0.69/LGPL\n",
            "cabocha-0.69/tools/\n",
            "cabocha-0.69/tools/kc2cabocha.pl\n",
            "cabocha-0.69/tools/irex2cabocha.pl\n",
            "cabocha-0.69/tools/chasen2mecab.pl\n",
            "cabocha-0.69/tools/kc2juman.pl\n",
            "cabocha-0.69/tools/KyotoCorpus.pm\n",
            "cabocha-0.69/tools/KNBC2KC.pl\n",
            "cabocha-0.69/cabocharc.in\n",
            "cabocha-0.69/INSTALL\n",
            "cabocha-0.69/aclocal.m4\n",
            "cabocha-0.69/README\n",
            "cabocha-0.69/config.h.in\n",
            "cabocha-0.69/COPYING\n",
            "cabocha-0.69/example/\n",
            "cabocha-0.69/example/example2.cpp\n",
            "cabocha-0.69/example/example.c\n",
            "cabocha-0.69/Makefile.am\n",
            "cabocha-0.69/model/\n",
            "cabocha-0.69/model/dep.ipa.txt\n",
            "cabocha-0.69/model/ne.juman.txt\n",
            "cabocha-0.69/model/dep.juman.txt\n",
            "cabocha-0.69/model/Makefile.in\n",
            "cabocha-0.69/model/dep.unidic.txt\n",
            "cabocha-0.69/model/chunk.ipa.txt\n",
            "cabocha-0.69/model/chunk.unidic.txt\n",
            "cabocha-0.69/model/ne.ipa.txt\n",
            "cabocha-0.69/model/ne.unidic.txt\n",
            "cabocha-0.69/model/chunk.juman.txt\n",
            "cabocha-0.69/model/Makefile.am\n",
            "cabocha-0.69/doc/\n",
            "cabocha-0.69/doc/README.txt\n",
            "cabocha-0.69/doc/doxygen/\n",
            "cabocha-0.69/doc/doxygen/classes.html\n",
            "cabocha-0.69/doc/doxygen/ftv2plastnode.png\n",
            "cabocha-0.69/doc/doxygen/nav_g.png\n",
            "cabocha-0.69/doc/doxygen/files.html\n",
            "cabocha-0.69/doc/doxygen/tab_b.gif\n",
            "cabocha-0.69/doc/doxygen/nav_h.png\n",
            "cabocha-0.69/doc/doxygen/namespaceCaboCha.html\n",
            "cabocha-0.69/doc/doxygen/functions_vars.html\n",
            "cabocha-0.69/doc/doxygen/tab_s.png\n",
            "cabocha-0.69/doc/doxygen/namespacemembers_eval.html\n",
            "cabocha-0.69/doc/doxygen/ftv2pnode.png\n",
            "cabocha-0.69/doc/doxygen/cabocha_8h.html\n",
            "cabocha-0.69/doc/doxygen/open.png\n",
            "cabocha-0.69/doc/doxygen/globals_func.html\n",
            "cabocha-0.69/doc/doxygen/structcabocha__token__t.html\n",
            "cabocha-0.69/doc/doxygen/doxygen.css\n",
            "cabocha-0.69/doc/doxygen/ftv2node.png\n",
            "cabocha-0.69/doc/doxygen/functions_func.html\n",
            "cabocha-0.69/doc/doxygen/ftv2mnode.png\n",
            "cabocha-0.69/doc/doxygen/ftv2doc.png\n",
            "cabocha-0.69/doc/doxygen/globals_enum.html\n",
            "cabocha-0.69/doc/doxygen/classCaboCha_1_1Tree.html\n",
            "cabocha-0.69/doc/doxygen/functions.html\n",
            "cabocha-0.69/doc/doxygen/ftv2folderopen.png\n",
            "cabocha-0.69/doc/doxygen/namespacemembers.html\n",
            "cabocha-0.69/doc/doxygen/globals.html\n",
            "cabocha-0.69/doc/doxygen/ftv2link.png\n",
            "cabocha-0.69/doc/doxygen/ftv2folderclosed.png\n",
            "cabocha-0.69/doc/doxygen/structcabocha__token__t-members.html\n",
            "cabocha-0.69/doc/doxygen/bdwn.png\n",
            "cabocha-0.69/doc/doxygen/namespacemembers_func.html\n",
            "cabocha-0.69/doc/doxygen/structcabocha__chunk__t.html\n",
            "cabocha-0.69/doc/doxygen/bc_s.png\n",
            "cabocha-0.69/doc/doxygen/cabocha_8h_source.html\n",
            "cabocha-0.69/doc/doxygen/globals_eval.html\n",
            "cabocha-0.69/doc/doxygen/ftv2mo.png\n",
            "cabocha-0.69/doc/doxygen/doxygen.png\n",
            "cabocha-0.69/doc/doxygen/index.html\n",
            "cabocha-0.69/doc/doxygen/tab_b.png\n",
            "cabocha-0.69/doc/doxygen/closed.png\n",
            "cabocha-0.69/doc/doxygen/nav_f.png\n",
            "cabocha-0.69/doc/doxygen/ftv2lastnode.png\n",
            "cabocha-0.69/doc/doxygen/classCaboCha_1_1Tree-members.html\n",
            "cabocha-0.69/doc/doxygen/tabs.css\n",
            "cabocha-0.69/doc/doxygen/ftv2vertline.png\n",
            "cabocha-0.69/doc/doxygen/ftv2cl.png\n",
            "cabocha-0.69/doc/doxygen/tab_h.png\n",
            "cabocha-0.69/doc/doxygen/globals_type.html\n",
            "cabocha-0.69/doc/doxygen/structcabocha__chunk__t-members.html\n",
            "cabocha-0.69/doc/doxygen/globals_defs.html\n",
            "cabocha-0.69/doc/doxygen/annotated.html\n",
            "cabocha-0.69/doc/doxygen/namespacemembers_type.html\n",
            "cabocha-0.69/doc/doxygen/tab_l.gif\n",
            "cabocha-0.69/doc/doxygen/tab_a.png\n",
            "cabocha-0.69/doc/doxygen/sync_off.png\n",
            "cabocha-0.69/doc/doxygen/ftv2ns.png\n",
            "cabocha-0.69/doc/doxygen/tab_r.gif\n",
            "cabocha-0.69/doc/doxygen/classCaboCha_1_1Parser-members.html\n",
            "cabocha-0.69/doc/doxygen/ftv2splitbar.png\n",
            "cabocha-0.69/doc/doxygen/ftv2mlastnode.png\n",
            "cabocha-0.69/doc/doxygen/classCaboCha_1_1Parser.html\n",
            "cabocha-0.69/doc/doxygen/namespaces.html\n",
            "cabocha-0.69/doc/doxygen/sync_on.png\n",
            "cabocha-0.69/doc/doxygen/namespacemembers_enum.html\n",
            "cabocha-0.69/doc/doxygen/dir_68267d1309a1af8e8297ef4c3efbcdba.html\n",
            "cabocha-0.69/doc/doxygen/dynsections.js\n",
            "cabocha-0.69/doc/doxygen/ftv2blank.png\n",
            "cabocha-0.69/doc/cabocha.cfg\n",
            "/cabocha-0.69\n",
            "checking for a BSD-compatible install... /usr/bin/install -c\n",
            "checking whether build environment is sane... yes\n",
            "checking for a thread-safe mkdir -p... /usr/bin/mkdir -p\n",
            "checking for gawk... no\n",
            "checking for mawk... mawk\n",
            "checking whether make sets $(MAKE)... yes\n",
            "checking whether make supports nested variables... yes\n",
            "checking whether to enable maintainer-specific portions of Makefiles... no\n",
            "checking for gcc... gcc\n",
            "checking whether the C compiler works... yes\n",
            "checking for C compiler default output file name... a.out\n",
            "checking for suffix of executables... \n",
            "checking whether we are cross compiling... no\n",
            "checking for suffix of object files... o\n",
            "checking whether we are using the GNU C compiler... yes\n",
            "checking whether gcc accepts -g... yes\n",
            "checking for gcc option to accept ISO C89... none needed\n",
            "checking whether gcc understands -c and -o together... yes\n",
            "checking for style of include used by make... GNU\n",
            "checking dependency style of gcc... none\n",
            "checking for g++... g++\n",
            "checking whether we are using the GNU C++ compiler... yes\n",
            "checking whether g++ accepts -g... yes\n",
            "checking dependency style of g++... none\n",
            "checking how to run the C preprocessor... gcc -E\n",
            "checking for grep that handles long lines and -e... /usr/bin/grep\n",
            "checking for egrep... /usr/bin/grep -E\n",
            "checking whether gcc needs -traditional... no\n",
            "checking whether make sets $(MAKE)... (cached) yes\n",
            "checking build system type... x86_64-unknown-linux-gnu\n",
            "checking host system type... x86_64-unknown-linux-gnu\n",
            "checking how to print strings... printf\n",
            "checking for a sed that does not truncate output... /usr/bin/sed\n",
            "checking for fgrep... /usr/bin/grep -F\n",
            "checking for ld used by gcc... /usr/bin/ld\n",
            "checking if the linker (/usr/bin/ld) is GNU ld... yes\n",
            "checking for BSD- or MS-compatible name lister (nm)... /usr/bin/nm -B\n",
            "checking the name lister (/usr/bin/nm -B) interface... BSD nm\n",
            "checking whether ln -s works... yes\n",
            "checking the maximum length of command line arguments... 1572864\n",
            "checking whether the shell understands some XSI constructs... yes\n",
            "checking whether the shell understands \"+=\"... yes\n",
            "checking how to convert x86_64-unknown-linux-gnu file names to x86_64-unknown-linux-gnu format... func_convert_file_noop\n",
            "checking how to convert x86_64-unknown-linux-gnu file names to toolchain format... func_convert_file_noop\n",
            "checking for /usr/bin/ld option to reload object files... -r\n",
            "checking for objdump... objdump\n",
            "checking how to recognize dependent libraries... pass_all\n",
            "checking for dlltool... dlltool\n",
            "checking how to associate runtime and link libraries... printf %s\\n\n",
            "checking for ar... ar\n",
            "checking for archiver @FILE support... @\n",
            "checking for strip... strip\n",
            "checking for ranlib... ranlib\n",
            "checking command to parse /usr/bin/nm -B output from gcc object... ok\n",
            "checking for sysroot... no\n",
            "checking for mt... no\n",
            "checking if : is a manifest tool... no\n",
            "checking for ANSI C header files... yes\n",
            "checking for sys/types.h... yes\n",
            "checking for sys/stat.h... yes\n",
            "checking for stdlib.h... yes\n",
            "checking for string.h... yes\n",
            "checking for memory.h... yes\n",
            "checking for strings.h... yes\n",
            "checking for inttypes.h... yes\n",
            "checking for stdint.h... yes\n",
            "checking for unistd.h... yes\n",
            "checking for dlfcn.h... yes\n",
            "checking for objdir... .libs\n",
            "checking if gcc supports -fno-rtti -fno-exceptions... no\n",
            "checking for gcc option to produce PIC... -fPIC -DPIC\n",
            "checking if gcc PIC flag -fPIC -DPIC works... yes\n",
            "checking if gcc static flag -static works... yes\n",
            "checking if gcc supports -c -o file.o... yes\n",
            "checking if gcc supports -c -o file.o... (cached) yes\n",
            "checking whether the gcc linker (/usr/bin/ld -m elf_x86_64) supports shared libraries... yes\n",
            "checking whether -lc should be explicitly linked in... no\n",
            "checking dynamic linker characteristics... GNU/Linux ld.so\n",
            "checking how to hardcode library paths into programs... immediate\n",
            "checking whether stripping libraries is possible... yes\n",
            "checking if libtool supports shared libraries... yes\n",
            "checking whether to build shared libraries... yes\n",
            "checking whether to build static libraries... yes\n",
            "checking how to run the C++ preprocessor... g++ -E\n",
            "checking for ld used by g++... /usr/bin/ld -m elf_x86_64\n",
            "checking if the linker (/usr/bin/ld -m elf_x86_64) is GNU ld... yes\n",
            "checking whether the g++ linker (/usr/bin/ld -m elf_x86_64) supports shared libraries... yes\n",
            "checking for g++ option to produce PIC... -fPIC -DPIC\n",
            "checking if g++ PIC flag -fPIC -DPIC works... yes\n",
            "checking if g++ static flag -static works... yes\n",
            "checking if g++ supports -c -o file.o... yes\n",
            "checking if g++ supports -c -o file.o... (cached) yes\n",
            "checking whether the g++ linker (/usr/bin/ld -m elf_x86_64) supports shared libraries... yes\n",
            "checking dynamic linker characteristics... (cached) GNU/Linux ld.so\n",
            "checking how to hardcode library paths into programs... immediate\n",
            "checking for library containing strerror... none required\n",
            "checking for ld used by gcc... /usr/bin/ld -m elf_x86_64\n",
            "checking if the linker (/usr/bin/ld -m elf_x86_64) is GNU ld... yes\n",
            "checking for shared library run path origin... done\n",
            "checking for iconv... yes\n",
            "checking for working iconv... yes\n",
            "checking for iconv declaration... \n",
            "         extern size_t iconv (iconv_t cd, char * *inbuf, size_t *inbytesleft, char * *outbuf, size_t *outbytesleft);\n",
            "checking for ANSI C header files... (cached) yes\n",
            "checking for an ANSI C-conforming const... yes\n",
            "checking whether byte ordering is bigendian... no\n",
            "checking for string.h... (cached) yes\n",
            "checking for stdlib.h... (cached) yes\n",
            "checking for unistd.h... (cached) yes\n",
            "checking fcntl.h usability... yes\n",
            "checking fcntl.h presence... yes\n",
            "checking for fcntl.h... yes\n",
            "checking for sys/stat.h... (cached) yes\n",
            "checking sys/mman.h usability... yes\n",
            "checking sys/mman.h presence... yes\n",
            "checking for sys/mman.h... yes\n",
            "checking sys/times.h usability... yes\n",
            "checking sys/times.h presence... yes\n",
            "checking for sys/times.h... yes\n",
            "checking for sys/types.h... (cached) yes\n",
            "checking dirent.h usability... yes\n",
            "checking dirent.h presence... yes\n",
            "checking for dirent.h... yes\n",
            "checking ctype.h usability... yes\n",
            "checking ctype.h presence... yes\n",
            "checking for ctype.h... yes\n",
            "checking for sys/types.h... (cached) yes\n",
            "checking io.h usability... no\n",
            "checking io.h presence... no\n",
            "checking for io.h... no\n",
            "checking windows.h usability... no\n",
            "checking windows.h presence... no\n",
            "checking for windows.h... no\n",
            "checking pthread.h usability... yes\n",
            "checking pthread.h presence... yes\n",
            "checking for pthread.h... yes\n",
            "checking for off_t... yes\n",
            "checking for size_t... yes\n",
            "checking size of char... 1\n",
            "checking size of short... 2\n",
            "checking size of int... 4\n",
            "checking size of long... 8\n",
            "checking size of long long... 8\n",
            "checking size of size_t... 8\n",
            "checking for size_t... (cached) yes\n",
            "checking for stdlib.h... (cached) yes\n",
            "checking for unistd.h... (cached) yes\n",
            "checking for sys/param.h... yes\n",
            "checking for getpagesize... yes\n",
            "checking for working mmap... yes\n",
            "checking for getenv... yes\n",
            "checking for opendir... yes\n",
            "checking for snprintf... yes\n",
            "checking for mecab-config... /usr/bin/mecab-config\n",
            "checking whether iconv supports EUC-JP-MS and CP932... checking for main in -lstdc++... yes\n",
            "checking for crfpp_new in -lcrfpp... no\n",
            "checking for mecab_new in -lmecab... yes\n",
            "checking if g++ supports stl <vector> (required)... yes\n",
            "checking if g++ supports stl <list> (required)... yes\n",
            "checking if g++ supports stl <map> (required)... yes\n",
            "checking if g++ supports stl <set> (required)... yes\n",
            "checking if g++ supports stl <queue> (required)... yes\n",
            "checking if g++ supports stl <functional> (required)... yes\n",
            "checking if g++ supports stl <algorithm> (required)... yes\n",
            "checking if g++ supports stl <string> (required)... yes\n",
            "checking if g++ supports stl <iostream> (required)... yes\n",
            "checking if g++ supports stl <strstream> (required)... yes\n",
            "checking if g++ supports stl <fstream> (required)... yes\n",
            "checking if g++ supports template <class T> (required)... yes\n",
            "checking if g++ supports const_cast<> (required)... yes\n",
            "checking if g++ supports static_cast<> (required)... yes\n",
            "checking if g++ supports dynamic_cast<> (required)... yes\n",
            "checking if g++ supports reinterpret_cast<> (required)... yes\n",
            "checking if g++ supports exception handler (required)... yes\n",
            "checking if g++ supports namespaces (required) ... yes\n",
            "checking if g++ supports __thread (optional)... yes\n",
            "checking if g++ environment provides all required features... yes\n",
            "checking that generated files are newer than configure... done\n",
            "configure: creating ./config.status\n",
            "config.status: creating Makefile\n",
            "config.status: creating src/Makefile\n",
            "config.status: creating src/Makefile.msvc\n",
            "config.status: creating model/Makefile\n",
            "config.status: creating man/Makefile\n",
            "config.status: creating swig/version.h\n",
            "config.status: creating cabocha-config\n",
            "config.status: creating cabocharc\n",
            "config.status: creating cabocha.iss\n",
            "config.status: creating config.h\n",
            "config.status: config.h is unchanged\n",
            "config.status: executing depfiles commands\n",
            "config.status: executing libtool commands\n",
            "config.status: executing default commands\n",
            "make  all-recursive\n",
            "make[1]: Entering directory '/cabocha-0.69'\n",
            "Making all in src\n",
            "make[2]: Entering directory '/cabocha-0.69/src'\n",
            "/bin/bash ../libtool  --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DCABOCHA_DEFAULT_POSSET=\"\\\"IPA\"\\\" -DCABOCHA_DEFAULT_CHARSET=\"\\\"utf-8\"\\\" -DMODEL_VERSION=102  -DCABOCHA_DEFAULT_RC=\"\\\"/usr/local/etc/cabocharc\\\"\"    -O3 -Wno-deprecated -Wall -c -o chunk_learner.lo chunk_learner.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DCABOCHA_DEFAULT_POSSET=\\\"IPA\\\" -DCABOCHA_DEFAULT_CHARSET=\\\"utf-8\\\" -DMODEL_VERSION=102 -DCABOCHA_DEFAULT_RC=\\\"/usr/local/etc/cabocharc\\\" -O3 -Wno-deprecated -Wall -c chunk_learner.cpp  -fPIC -DPIC -o .libs/chunk_learner.o\n",
            "\u001b[01m\u001b[Kchunk_learner.cpp:6:10:\u001b[m\u001b[K \u001b[01;31m\u001b[Kfatal error: \u001b[m\u001b[Kcrfpp.h: No such file or directory\n",
            "    6 | #include \u001b[01;31m\u001b[K<crfpp.h>\u001b[m\u001b[K\n",
            "      |          \u001b[01;31m\u001b[K^~~~~~~~~\u001b[m\u001b[K\n",
            "compilation terminated.\n",
            "make[2]: *** [Makefile:597: chunk_learner.lo] Error 1\n",
            "make[2]: Leaving directory '/cabocha-0.69/src'\n",
            "make[1]: *** [Makefile:508: all-recursive] Error 1\n",
            "make[1]: Leaving directory '/cabocha-0.69'\n",
            "make: *** [Makefile:375: all] Error 2\n",
            "/\n",
            "/bin/bash: line 1: cabocha: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Morph:\n",
        "  def __init__(self, line):\n",
        "    surface, other = line.split(\"\\t\")\n",
        "    other = other.split(\",\")\n",
        "    self.surface = surface\n",
        "    self.base = other[-3]\n",
        "    self.pos = other[0]\n",
        "    self.pos1 = other[1]\n",
        "\n",
        "sentences = [] #文リスト\n",
        "morphs = [] #形態素リスト\n",
        "\n",
        "with open(\"./ai.ja.txt.parsed\") as f:\n",
        "  for line in f:\n",
        "    if line[0] == \"*\":\n",
        "      continue\n",
        "    elif line != \"EOS\\n\":\n",
        "      morphs.append(Morph(line))\n",
        "    else:  #EOS（文末）の場合\n",
        "      sentences.append(morphs)\n",
        "      morphs = []\n",
        "\n",
        "for i in sentences[0]:\n",
        "    print(vars(i))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "-0cTMRBPX_cp",
        "outputId": "0644caf2-5ce0-419e-dcfc-21c02c80b7f7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-2a34ba886a27>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mmorphs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#形態素リスト\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./ai.ja.txt.parsed\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"*\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './ai.ja.txt.parsed'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "問４１"
      ],
      "metadata": {
        "id": "7D-x_pGwWzg_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Sentence:\n",
        "  def __init__(self, chunks):\n",
        "    self.chunks = chunks\n",
        "    for i, chunk in enumerate(self.chunks):\n",
        "      if chunk.dst not in [None, -1]:\n",
        "        self.chunks[chunk.dst].srcs.append(i)\n",
        "\n",
        "class Chunk:\n",
        "  def __init__(self, morphs, dst, chunk_id):\n",
        "    self.morphs = morphs\n",
        "    self.dst = dst\n",
        "    self.srcs = []\n",
        "    self.chunk_id = chunk_id\n",
        "\n",
        "class Morph:\n",
        "  def __init__(self, line):\n",
        "    surface, other = line.split(\"\\t\")\n",
        "    other = other.split(\",\")\n",
        "    self.surface = surface\n",
        "    self.base = other[-3]\n",
        "    self.pos = other[0]\n",
        "    self.pos1 = other[1]\n",
        "\n",
        "sentences = [] #文リスト\n",
        "chunks = [] #節リスト\n",
        "morphs = [] #形態素リスト\n",
        "chunk_id = 0 #文節番号\n",
        "\n",
        "with open(\"./ai.ja.txt.parsed\") as f:\n",
        "  for line in f:\n",
        "    if line[0] == \"*\":\n",
        "      if morphs:\n",
        "        chunks.append(Chunk(morphs, dst, chunk_id))\n",
        "        chunk_id += 1\n",
        "        morphs = []\n",
        "      dst = int(line.split()[2].replace(\"D\", \"\"))\n",
        "    elif line != \"EOS\\n\":\n",
        "      morphs.append(Morph(line))\n",
        "    else:\n",
        "      chunks.append(Chunk(morphs, dst, chunk_id))\n",
        "      sentences.append(Sentence(chunks))\n",
        "\n",
        "      morphs = []\n",
        "      chunks = []\n",
        "      dst = None\n",
        "      chunk_id = 0\n",
        "\n",
        "for chunk in sentences[2].chunks:\n",
        "  chunk_str = \"\".join([morph.surface for morph in chunk.morphs])\n",
        "  print(f\"文節の文字列：{chunk_str}\\n係り先の文節番号：{chunk.dst}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "qobxEH83XUju",
        "outputId": "40361af3-25d6-4e07-f204-833a1b1a8de2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-78578ca37fbb>\u001b[0m in \u001b[0;36m<cell line: 29>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mchunk_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;31m#文節番号\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./ai.ja.txt.parsed\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"*\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './ai.ja.txt.parsed'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "問４２"
      ],
      "metadata": {
        "id": "OjvRhfI_WztQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for chunk in sentences[2].chunks:\n",
        "  if int(chunk.dst) == -1:\n",
        "    continue\n",
        "  else:\n",
        "    surf = \"\".join([morph.surface for morph in chunk.morphs if morph.pos != \"記号\"])\n",
        "    next_surf = \"\".join([morph.surface for morph in sentences[2].chunks[int(chunk.dst)].morphs if morph.pos != \"記号\"])\n",
        "    print(f\"{surf}\\t{next_surf}\")"
      ],
      "metadata": {
        "id": "2c4sGZM4XVBa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "問４３"
      ],
      "metadata": {
        "id": "qM2NxNtNXGqW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for chunk in sentences[2].chunks:\n",
        "  if int(chunk.dst) == -1:\n",
        "    continue\n",
        "  else:\n",
        "    surf = \"\".join([morph.surface for morph in chunk.morphs if morph.pos != \"記号\"])\n",
        "    next_surf = \"\".join([morph.surface for morph in sentences[2].chunks[int(chunk.dst)].morphs if morph.pos != \"記号\"])\n",
        "    pos_noun = [morph.surface for morph in chunk.morphs if morph.pos == \"名詞\"]\n",
        "    pos_verb = [morph.surface for morph in sentences[2].chunks[int(chunk.dst)].morphs if morph.pos == \"動詞\"]\n",
        "    if pos_noun and pos_verb:\n",
        "      print(f\"{surf}\\t{next_surf}\")"
      ],
      "metadata": {
        "id": "PSLt4-lvXVZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "問４４"
      ],
      "metadata": {
        "id": "iXdpltzjXKLK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#pydotをインストール\n",
        "!pip install pydot\n",
        "#日本語フォントをインストール\n",
        "!apt install fonts-ipafont-gothic\n",
        "\n",
        "import pydot_ng as pydot\n",
        "\n",
        "pair = []\n",
        "for chunk in sentences[2].chunks:\n",
        "  if int(chunk.dst) == -1:\n",
        "    continue\n",
        "  else:\n",
        "    surf = \"\".join([morph.surface for morph in chunk.morphs if morph.pos != \"記号\"])\n",
        "    next_surf = \"\".join([morph.surface for morph in sentences[2].chunks[int(chunk.dst)].morphs if morph.pos != \"記号\"]) #文節のリストに係り先番号をindexに指定。その文節の形態素リストを取得\n",
        "    pair.append((surf, next_surf))\n",
        "\n",
        "img = pydot.Dot()\n",
        "img.set_node_defaults(fontname=\"MS Mincho\")\n",
        "for s, t in pair:\n",
        "  img.add_edge(pydot.Edge(s, t))\n",
        "img.write_png(\"./result44.png\")"
      ],
      "metadata": {
        "id": "Zl5XxShOXVz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "問４５"
      ],
      "metadata": {
        "id": "F3UzbDdRXKkZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"./result45.txt\", \"w\") as f:\n",
        "  for i in range(len(sentences)):\n",
        "    for chunk in sentences[i].chunks:\n",
        "      for morph in chunk.morphs:\n",
        "        if morph.pos == \"動詞\":\n",
        "          particles = []\n",
        "          for src in chunk.srcs:\n",
        "            particles += [morph.surface for morph in sentences[i].chunks[src].morphs if morph.pos == \"助詞\"]\n",
        "          if len(particles) > 1:\n",
        "            particles = set(particles)\n",
        "            particles = sorted(list(particles))\n",
        "            form = \" \".join(particles)\n",
        "            print(f\"{morph.base}\\t{form}\", file=f)"
      ],
      "metadata": {
        "id": "QCFMWCAAXWVa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#コーパス中で頻出する述語と格パターンの組み合わせ\n",
        "!cat ./result45.txt | sort | uniq -c | sort -nr | head -n 5\n",
        "#「行う」「なる」「与える」という動詞の格パターン\n",
        "!cat ./result45.txt |grep \"行う\" | sort |uniq -c | sort -nr |head -n 5\n",
        "!cat ./result45.txt |grep \"なる\" | sort |uniq -c | sort -nr |head -n 5\n",
        "!cat ./result45.txt |grep \"与える\" | sort |uniq -c | sort -nr |head -n 5"
      ],
      "metadata": {
        "id": "43Cpd03wioNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "問４６"
      ],
      "metadata": {
        "id": "UKu6vd1DXNHo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"./result46.txt\", \"w\") as f:\n",
        "  for i in range(len(sentences)):\n",
        "    for chunk in sentences[i].chunks:\n",
        "      for morph in chunk.morphs:\n",
        "        if morph.pos == \"動詞\":\n",
        "          particles = []\n",
        "          items = []\n",
        "          for src in chunk.srcs:\n",
        "            particles += [morph.surface for morph in sentences[i].chunks[src].morphs if morph.pos == \"助詞\"]\n",
        "            items += [\"\".join([morph.surface for morph in sentences[i].chunks[src].morphs if morph.pos != \"記号\"])]\n",
        "          if len(particles) > 1:\n",
        "            if len(items) > 1:\n",
        "              particles = sorted(set(particles))\n",
        "              items = sorted(set(items))\n",
        "              particles_form = \" \".join(particles)\n",
        "              items_form = \" \".join(items)\n",
        "              print(f\"{morph.base}\\t{particles_form}\\t{items_form}\", file=f)"
      ],
      "metadata": {
        "id": "9XuMMXekXWqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "問４７"
      ],
      "metadata": {
        "id": "FujIqOB8XNlk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"./result47.txt\", \"w\") as f:\n",
        "  for sentence in sentences:\n",
        "    for chunk in sentence.chunks:\n",
        "      for morph in chunk.morphs:\n",
        "        if morph.pos == \"動詞\":\n",
        "          for src in chunk.srcs:\n",
        "            predicates = []\n",
        "            if len(sentence.chunks[src].morphs) == 2 and sentence.chunks[src].morphs[0].pos1 == \"サ変接続\" and sentence.chunks[src].morphs[1].surface == \"を\":\n",
        "              predicates = \"\".join([sentence.chunks[src].morphs[0].surface, sentence.chunks[src].morphs[1].surface, morph.base])\n",
        "              particles = []\n",
        "              items = []\n",
        "              for src in chunk.srcs:\n",
        "                particles += [morph.surface for morph in sentence.chunks[src].morphs if morph.pos == \"助詞\"]\n",
        "                item = \"\".join([morph.surface for morph in sentence.chunks[src].morphs if morph.pos != \"記号\"])\n",
        "                item = item.rstrip()\n",
        "                if item not in predicates:\n",
        "                  items.append(item)\n",
        "              if len(particles) > 1:\n",
        "                if len(items) > 1:\n",
        "                  particles = sorted(set(particles))\n",
        "                  items = sorted(set(items))\n",
        "                  particles_form = \" \".join(particles)\n",
        "                  items_form = \" \".join(items)\n",
        "                  predicate = \" \".join(predicates)\n",
        "                  print(f\"{predicates}\\t{particles_form}\\t{items_form}\", file=f)"
      ],
      "metadata": {
        "id": "lkVuMNtGXXGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "問４８"
      ],
      "metadata": {
        "id": "SAtcPOM5XN9S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = sentences[2]\n",
        "for chunk in sentence.chunks:\n",
        "  for morph in chunk.morphs:\n",
        "    if \"名詞\" in morph.pos:\n",
        "      path = [\"\".join(morph.surface for morph in chunk.morphs if morph.pos != \"記号\")]\n",
        "      while chunk.dst != -1:\n",
        "        path.append(\"\".join(morph.surface for morph in sentence.chunks[chunk.dst].morphs if morph.pos != \"記号\"))\n",
        "        chunk = sentence.chunks[chunk.dst]\n",
        "      print(\"->\".join(path))"
      ],
      "metadata": {
        "id": "W2gktMzeXXkT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "問４９"
      ],
      "metadata": {
        "id": "eRdn1VOSXOS4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import combinations\n",
        "import re\n",
        "\n",
        "sentence = sentences[2]\n",
        "nouns = []\n",
        "for i, chunk in enumerate(sentence.chunks):\n",
        "  if [morph for morph in chunk.morphs if morph.pos == \"名詞\"]:\n",
        "    nouns.append(i)\n",
        "for i, j in combinations(nouns, 2):\n",
        "  path_I = []\n",
        "  path_J = []\n",
        "  while i != j:\n",
        "    if i < j: #文節iの構文木経路上に文節jが存在する場合\n",
        "      path_I.append(i)\n",
        "      i = sentence.chunks[i].dst\n",
        "    else: #文節iの構文木経路上に文節jがない場合\n",
        "      path_J.append(j)\n",
        "      j = sentence.chunks[j].dst\n",
        "\n",
        "  if len(path_J) == 0: # 文節Iの構文木上に文節Jが存在する場合\n",
        "    X = \"X\" + \"\".join([morph.surface for morph in sentence.chunks[path_I[0]].morphs if morph.pos != \"名詞\" and morph.pos != \"記号\"])\n",
        "    Y = \"Y\" +  \"\".join([morph.surface for morph in sentence.chunks[i].morphs if morph.pos != \"名詞\" and morph.pos != \"記号\"])\n",
        "    chunk_X = re.sub(\"X+\", \"X\", X)\n",
        "    chunk_Y = re.sub(\"Y+\", \"Y\", Y)\n",
        "    path_ItoJ = [chunk_X] + [\"\".join(morph.surface for n in path_I[1:] for morph in sentence.chunks[n].morphs)] + [chunk_Y]\n",
        "    print(\" -> \".join(path_ItoJ))\n",
        "  else: # 文節Iの構文木上に文節Jが存在しない場合\n",
        "    X = \"X\" + \"\".join([morph.surface for morph in sentence.chunks[path_I[0]].morphs if morph.pos != \"名詞\" and morph.pos != \"記号\"])\n",
        "    Y = \"Y\" + \"\".join([morph.surface for morph in sentence.chunks[path_J[0]].morphs if morph.pos != \"名詞\" and morph.pos != \"記号\"])\n",
        "    chunk_X = re.sub(\"X+\", \"X\", X)\n",
        "    chunk_Y = re.sub(\"Y+\", \"Y\", Y)\n",
        "    chunk_k = \"\".join([morph.surface for morph in sentence.chunks[i].morphs if morph.pos != \"記号\"])\n",
        "    path_X = [chunk_X] + [\"\".join(morph.surface for n in path_I[1:] for morph in sentence.chunks[n].morphs if morph.pos != \"記号\")]\n",
        "    path_Y = [chunk_Y] + [\"\".join(morph.surface for n in path_J[1: ]for morph in sentence.chunks[n].morphs if morph.pos != \"記号\")]\n",
        "    print(\" | \".join([\"->\".join(path_X), \"->\".join(path_Y), chunk_k]))"
      ],
      "metadata": {
        "id": "0Lq4iTzQXX_Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}